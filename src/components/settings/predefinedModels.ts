// D√©finition de l'interface AIModel directement dans ce fichier pour √©viter les probl√®mes d'importation
export interface AIModel {
  id: string;
  name: string;
  provider: 'openai' | 'google' | 'anthropic' | 'azure' | 'mistral' | 'cohere' | 'local' | 'deepseek' | 'ollama' | 'other';
  modelId: string;
  isDefault: boolean;
  capabilities: {
    chat: boolean;
    completion: boolean;
    embeddings: boolean;
    vision: boolean;
    audio: boolean;
  };
  contextWindow: number;
  costPer1kTokens: {
    input: number;
    output: number;
  };
  maxTokens: number;
  description: string;
  tags: string[];
  version: string;
}

export type PredefinedModelTemplate = Omit<AIModel, 'id' | 'isDefault'>;

export const predefinedModels: Record<string, PredefinedModelTemplate> = {
  'gpt-4-turbo': {
    name: 'GPT-4 Turbo',
    provider: 'openai',
    modelId: 'gpt-4-turbo-2024-04-09',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: true,
      audio: false,
    },
    contextWindow: 128000,
    costPer1kTokens: {
      input: 0.01,
      output: 0.03,
    },
    maxTokens: 4096,
    description: 'Mod√®le avanc√© d\'OpenAI avec excellente compr√©hension et capacit√©s multimodales. Version d\'avril 2024.',
    tags: ['openai', 'chat', 'vision', 'multimodal'],
    version: '2024-04-09',
  },
  'gpt-4o': {
    name: 'GPT-4o',
    provider: 'openai',
    modelId: 'gpt-4o-2024-05-13',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: true,
      audio: true,
    },
    contextWindow: 128000,
    costPer1kTokens: {
      input: 0.005,
      output: 0.015,
    },
    maxTokens: 4096,
    description: 'Le mod√®le phare d\'OpenAI, combinant performances √©lev√©es et co√ªt r√©duit. Supporte l\'audio et la vision.',
    tags: ['openai', 'chat', 'vision', 'audio', 'multimodal'],
    version: '2024-05-13',
  },
  'gpt-3.5-turbo': {
    name: 'GPT-3.5 Turbo',
    provider: 'openai',
    modelId: 'gpt-3.5-turbo-0125',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 16385,
    costPer1kTokens: {
      input: 0.0005,
      output: 0.0015,
    },
    maxTokens: 4096,
    description: 'Mod√®le rapide et √©conomique pour la plupart des cas d\'utilisation. Excellent rapport performance/co√ªt.',
    tags: ['openai', 'chat', '√©conomique', 'rapide'],
    version: '0125',
  },
  'claude-3-opus': {
    name: 'Claude 3 Opus',
    provider: 'anthropic',
    modelId: 'claude-3-opus-20240229',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: true,
      audio: false,
    },
    contextWindow: 200000,
    costPer1kTokens: {
      input: 0.015,
      output: 0.075,
    },
    maxTokens: 4096,
    description: 'Mod√®le le plus puissant d\'Anthropic avec raisonnement avanc√©, analyse complexe et compr√©hension nuanc√©e.',
    tags: ['anthropic', 'claude', 'vision', 'raisonnement'],
    version: '20240229',
  },
  'claude-3-sonnet': {
    name: 'Claude 3 Sonnet',
    provider: 'anthropic',
    modelId: 'claude-3-sonnet-20240229',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: true,
      audio: false,
    },
    contextWindow: 200000,
    costPer1kTokens: {
      input: 0.003,
      output: 0.015,
    },
    maxTokens: 4096,
    description: '√âquilibre optimal entre performances et co√ªt. Id√©al pour applications professionnelles et assistance.',
    tags: ['anthropic', 'claude', 'vision', '√©quilibr√©'],
    version: '20240229',
  },
  'claude-3-haiku': {
    name: 'Claude 3 Haiku',
    provider: 'anthropic',
    modelId: 'claude-3-haiku-20240307',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: true,
      audio: false,
    },
    contextWindow: 200000,
    costPer1kTokens: {
      input: 0.00025,
      output: 0.00125,
    },
    maxTokens: 4096,
    description: 'Mod√®le ultra-rapide pour applications temps r√©el. Co√ªt tr√®s bas, id√©al pour chatbots et assistance.',
    tags: ['anthropic', 'claude', 'rapide', 'vision', '√©conomique'],
    version: '20240307',
  },
  'gemini-1.5-pro': {
    name: 'Gemini 1.5 Pro',
    provider: 'google',
    modelId: 'gemini-1.5-pro-latest',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: true,
      audio: true,
    },
    contextWindow: 1000000,
    costPer1kTokens: {
      input: 0.0005,
      output: 0.0015,
    },
    maxTokens: 8192,
    description: 'Mod√®le multimodal de Google avec fen√™tre contextuelle d\'1M tokens. Excellent pour l\'analyse de documents longs.',
    tags: ['google', 'gemini', 'vision', 'audio', 'multimodal', 'contexte long'],
    version: 'latest',
  },
  'mistral-large': {
    name: 'Mistral Large',
    provider: 'mistral',
    modelId: 'mistral-large-2405',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 32768,
    costPer1kTokens: {
      input: 0.008,
      output: 0.024,
    },
    maxTokens: 8192,
    description: 'Mod√®le phare de Mistral AI. Performances exceptionnelles pour le code, le raisonnement et l\'analyse.',
    tags: ['mistral', 'code', 'raisonnement', 'analyse'],
    version: '2405',
  },
  'mistral-medium': {
    name: 'Mistral Medium',
    provider: 'mistral',
    modelId: 'mistral-medium-2312',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 32768,
    costPer1kTokens: {
      input: 0.0027,
      output: 0.0081,
    },
    maxTokens: 8192,
    description: '√âquilibre optimal entre performances et co√ªt. Id√©al pour applications d\'entreprise et assistants.',
    tags: ['mistral', '√©quilibr√©', 'entreprise'],
    version: '2312',
  },
  'mistral-small': {
    name: 'Mistral Small',
    provider: 'mistral',
    modelId: 'mistral-small-2402',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 32768,
    costPer1kTokens: {
      input: 0.0006,
      output: 0.0018,
    },
    maxTokens: 8192,
    description: 'Mod√®le l√©ger et √©conomique pour applications √† fort volume. Excellent pour chatbots et assistants simples.',
    tags: ['mistral', '√©conomique', 'rapide', 'volume'],
    version: '2402',
  },
  'cohere-command': {
    name: 'Cohere Command',
    provider: 'cohere',
    modelId: 'command',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 128000,
    costPer1kTokens: {
      input: 0.0015,
      output: 0.0015,
    },
    maxTokens: 4096,
    description: 'Mod√®le optimis√© pour suivre des instructions pr√©cises avec un excellent contr√¥le.',
    tags: ['cohere', 'instructions'],
    version: '1.0',
  },
  'llama-3-70b': {
    name: 'Llama 3 70B',
    provider: 'local',
    modelId: 'llama-3-70b',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 8192,
    costPer1kTokens: {
      input: 0,
      output: 0,
    },
    maxTokens: 4096,
    description: 'Mod√®le open-source de Meta pour d√©ploiement local, tr√®s performant.',
    tags: ['meta', 'llama', 'open-source', 'local'],
    version: '1.0',
  },
  'deepseek-coder': {
    name: 'DeepSeek Coder',
    provider: 'deepseek',
    modelId: 'deepseek-coder-33b-instruct',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 32768,
    costPer1kTokens: {
      input: 0.0002,
      output: 0.0008,
    },
    maxTokens: 8192,
    description: 'Mod√®le sp√©cialis√© pour la g√©n√©ration et compr√©hension de code. Excellent pour le d√©veloppement logiciel.',
    tags: ['deepseek', 'code', 'programmation'],
    version: '33b-instruct',
  },
  'deepseek-llm': {
    name: 'DeepSeek LLM',
    provider: 'deepseek',
    modelId: 'deepseek-llm-67b-chat',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 32768,
    costPer1kTokens: {
      input: 0.0003,
      output: 0.0009,
    },
    maxTokens: 8192,
    description: 'Mod√®le g√©n√©raliste de DeepSeek avec d\'excellentes capacit√©s de raisonnement et de compr√©hension.',
    tags: ['deepseek', 'chat', 'raisonnement'],
    version: '67b-chat',
  },
  'gemini-1.5-flash': {
    name: 'Gemini 1.5 Flash',
    provider: 'google',
    modelId: 'gemini-1.5-flash-latest',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: true,
      audio: true,
    },
    contextWindow: 1000000,
    costPer1kTokens: {
      input: 0.00035,
      output: 0.00105,
    },
    maxTokens: 8192,
    description: 'Version rapide et √©conomique de Gemini 1.5 avec une fen√™tre contextuelle d\'1M tokens.',
    tags: ['google', 'gemini', 'vision', 'audio', 'multimodal', 'contexte long'],
    version: 'latest',
  },
  'gemini-1.0-pro': {
    name: 'Gemini 1.0 Pro',
    provider: 'google',
    modelId: 'gemini-1.0-pro-latest',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: true,
      audio: false,
    },
    contextWindow: 32768,
    costPer1kTokens: {
      input: 0.000125,
      output: 0.000375,
    },
    maxTokens: 8192,
    description: 'Mod√®le multimodal √©quilibr√© de Google avec un excellent rapport qualit√©-prix.',
    tags: ['google', 'gemini', 'vision', 'multimodal', '√©conomique'],
    version: 'latest',
  },
  'ollama-llama3': {
    name: 'Ollama Llama 3',
    provider: 'ollama',
    modelId: 'llama3',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 8192,
    costPer1kTokens: {
      input: 0,
      output: 0,
    },
    maxTokens: 4096,
    description: 'Mod√®le Llama 3 optimis√© pour ex√©cution locale via Ollama. Gratuit et performant.',
    tags: ['ollama', 'llama', 'local', 'gratuit'],
    version: '8b',
  },
  'ollama-mistral': {
    name: 'Ollama Mistral',
    provider: 'ollama',
    modelId: 'mistral',
    capabilities: {
      chat: true,
      completion: true,
      embeddings: false,
      vision: false,
      audio: false,
    },
    contextWindow: 8192,
    costPer1kTokens: {
      input: 0,
      output: 0,
    },
    maxTokens: 4096,
    description: 'Mod√®le Mistral optimis√© pour ex√©cution locale via Ollama. Id√©al pour les applications locales.',
    tags: ['ollama', 'mistral', 'local', 'gratuit'],
    version: '7b',
  },
};

export const getProviderIcon = (provider: string) => {
  switch (provider) {
    case 'openai': return 'üü¢';
    case 'anthropic': return 'üü£';
    case 'google': return 'üîµ';
    case 'mistral': return 'üü†';
    case 'cohere': return 'üüü';
    case 'azure': return 'üìó';
    case 'local': return 'üû¥';
    case 'deepseek': return 'üêå';
    case 'ollama': return 'üêò';
    default: return '‚ö™';
  }
};

export const getProviderLabel = (provider: string) => {
  switch (provider) {
    case 'openai': return 'OpenAI';
    case 'anthropic': return 'Anthropic';
    case 'google': return 'Google AI';
    case 'mistral': return 'Mistral AI';
    case 'cohere': return 'Cohere';
    case 'azure': return 'Azure OpenAI';
    case 'local': return 'Local';
    case 'deepseek': return 'DeepSeek AI';
    case 'ollama': return 'Ollama';
    default: return 'Autre';
  }
};

export const getCapabilityLabel = (capability: string) => {
  switch (capability) {
    case 'chat': return 'Chat';
    case 'completion': return 'Compl√©tion';
    case 'embeddings': return 'Embeddings';
    case 'vision': return 'Vision';
    case 'audio': return 'Audio';
    default: return capability;
  }
};

export const formatCost = (cost: number) => {
  if (cost === 0) return 'Gratuit';
  if (cost < 0.001) return `${(cost * 1000000).toFixed(2)} ¬µ$`;
  if (cost < 0.01) return `${(cost * 1000).toFixed(2)} m$`;
  return `${cost.toFixed(4)} $`;
};
